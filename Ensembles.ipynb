{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import keras\n",
    "import model01\n",
    "import datasets\n",
    "import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnsembleModel():\n",
    "    def __init(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def predict(self, X, **kwargs):\n",
    "        preds = [ model.predict(X, **kwargs) for model in self.models]\n",
    "        predicted_classes = [utils.prediction_to_category2(prediction) for prediction in preds]\n",
    "        print \"preds\", preds[:5]\n",
    "        print \"pred classes\", predicted_classes[:5]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_name_from_weights_file(wf):\n",
    "    return \"-\".join(wf[9:-5].split('-')[:-2])\n",
    "\n",
    "\n",
    "def report_performance(model_details, \n",
    "                       X_test, Y_test, prices_test, title, \n",
    "                       learning_curve=False, ylims=(0.68,0.70), **kwargs):\n",
    "    \n",
    "    name, weight_file = model_details\n",
    "    weight_file = './output/' + weight_file\n",
    "    model = keras.models.load_model(weight_file)\n",
    "    \n",
    "    \n",
    "    Y_test_pred = model.predict(X_test.as_matrix(), batch_size=1024)\n",
    "    print name\n",
    "    metrics.performance_report(title,  prices_test,  lookahead, Y_test, Y_test_pred, **kwargs)\n",
    "    if learning_curve:\n",
    "        pc = model01.ProgressCallback.load(model_name_from_weights_file(weight_file))\n",
    "        plot_learning_curve(pc, name, ylims)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_details):\n",
    "    name, weight_file = model_details\n",
    "    weight_file = './output/' + weight_file\n",
    "    model = keras.models.load_model(weight_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_MODELS = [\n",
    "    ['100 dropout=0', 'MLPModel01_20170423_1307_EURUSD_DS3_20092014_LA1_F99_C2_L100_DO0-1000-0.6945.hdf5'],\n",
    "    ['100x100 dropout=0','MLPModel01_20170423_1448_EURUSD_DS3_20092014_LA1_F99_C2_L100_100_DO0-1000-0.6928.hdf5'],\n",
    "    ['500 dropout=0','MLPModel01_20170423_1615_EURUSD_DS3_20092014_LA1_F99_C2_L500_DO0-1000-0.6949.hdf5'],\n",
    "    ['500x500 dropout=0 epoch 1000', 'MLPModel01_20170423_1800_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_DO0-1000-0.7095.hdf5'],\n",
    "    ['500x500 dropout=0.5','MLPModel01_20170423_2154_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_DO0.5-1000-0.6914.hdf5'],\n",
    "    ['100x100x100 dropout=0.5', 'MLPModel01_20170418_1151_EURUSD_DS3_20092014_LA1_F99_C2_L100_100_100_DO0.5-1005-0.6913.hdf5'],\n",
    "    ['500x500x500 dropout=0',   'MLPModel01_20170423_1051_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_500_DO0-015-0.6941.hdf5'],\n",
    "    ['500x500x500 dropout=0.5', 'MLPModel01_20170424_0713_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_500_DO0.5-2000-0.6913.hdf5'],\n",
    "    ['500x500x500 dropout=0.5 epoch 1970', 'MLPModel01_20170424_0713_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_500_DO0.5-1970-0.6912.hdf5'],\n",
    "    \n",
    "\n",
    "    ['100x100x100 dropout=0 epoch 20',  'MLPModel01_20170418_1912_EURUSD_DS3_20092014_LA1_F99_C2_L100_100_100_DO0-020-0.6932.hdf5'],\n",
    "    ['100x100x100 dropout=0 epoch 115', 'MLPModel01_20170418_1912_EURUSD_DS3_20092014_LA1_F99_C2_L100_100_100_DO0-115-0.6934.hdf5'],\n",
    "    ['500x500 dropout=0 epoch 165', 'MLPModel01_20170423_1800_EURUSD_DS3_20092014_LA1_F99_C2_L500_500_DO0-165-0.6954.hdf5'],\n",
    "    ['32x32x32x32 dropout=0.5', 'MLPModel01_20170423_1239_EURUSD_DS3_20092014_LA1_F99_C2_L32_32_32_32_DO0.5-455-0.6931.hdf5'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "lookahead=1\n",
    "dataset = 'DS3'\n",
    "window=25\n",
    "sym='EURUSD'\n",
    "\n",
    "year=2015\n",
    "test_title = sym + \" \" + str(year)\n",
    "X_test, Y_test, prices_test = datasets.load(datasets.filename(dataset, lookahead, window, sym, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model00 = joblib.load('./output/gnb_EURUSD_DS3_20092014.pkl') \n",
    "\n",
    "model01 = load_model(BEST_MODELS[0])\n",
    "model02 = load_model(BEST_MODELS[1])\n",
    "model03 = load_model(BEST_MODELS[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5158666666666667, 0.52373333333333338, 0.50980000000000003]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50480000000000003"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [ load_model(BEST_MODELS[i]) for i in [4,9] ] + [model00]\n",
    "N_SAMPLES = 15000\n",
    "\n",
    "act = np.matrix(Y_test.head(N_SAMPLES).ravel())\n",
    "comp = [ utils.prediction_to_category2(model.predict(X_test.head(N_SAMPLES).as_matrix())).ravel() for model in models]\n",
    "print [ (p == act).sum()*1.0/N_SAMPLES for p in comp ]\n",
    "\n",
    "pred = utils.prediction_to_category2(np.matrix(comp).sum(axis=0)/len(models))*1\n",
    "\n",
    "\n",
    "\n",
    "(pred == act).sum() *1.0/ N_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
